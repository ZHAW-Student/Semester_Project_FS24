---
title: Differentiation of walking patterns
subtitle: An attempt to differntiate walking patterns based on attributes and context information
author: Saskia Gianola and Sarah Wirth
format:
  html:
    code-fold: true
execute:
  warning: false
  message: false
lang: en  # switch to "de" if you write your report in german
bibliography: bibliography.bib
toc: true
---

```{r preprocessing}
#| code-summary: Preprocessing
# load libraries
library("XML")
library("leaflet")
library("sf")
library("tmap")
library("ggplot2")
library("tidyverse")
library("readr")
library("trajr")
library("yardstick")
library("caret") 

```

## Abstract

The main question this paper attempts to answer is whether it is possible to differentiate between the walking pattern from recreation, travel and shopping. Data is collected with the Strava App. Three approaches are developed, tested and evaluated. The first approach is a classification based on the attributes speed, step length and acceleration. The second approach is a classification based on the surroundings. The third approach is the development of a CART-tree that combines the attributes generated in the first approach and the context information from the second approach. We can conclude that the attribute-based classification is not able to cleanly separate travel and recreation. For shopping, there was no clear pattern to be found, as the GPS signal is most often lost in the building.

## Introduction

The aim of this paper is to test and compare different approaches to detect walking patterns. The different patterns that should be able to be distinguished are walking for recreational purposes, walking for commuting and shopping. The underlying idea is that the pattern of these walking types differs in their attributes and the environment that there are based in. It was already shown that a differentiation between transit and walking based on speed is possible [@kim_new_2012]. Also, outdoor walking activities are generally longer, more continuous and faster with the walking duration being the most important attribute for classification [@baroudi_classification_2024].\
Based on walking data tracked with the Strava app, we want to answer the following research questions:\
- How well it possible to derive the type of activity from movement data considering the attributes sinuosity, speed and visited locations?\
- Which type of analytical approach performs best in differentiating between the different activities?\
- Does the performance of the analytical concepts differ when applied on trajectories recorded by different people?\
The three approaches used in this study are classification based on attributes of the trajectory, CAMA-analysis and classification based on CART tree. The approaches are described in detail in the chapter material and methods.

## Material and Methods

### Data

Data was collected with the Strava App from March to June 2024. The training data for the development of the algorithms consists of 12 trajectories recorded by Saskia in March and April 2024. There are 13'636 attributed points. Additional data is collected by Saskia and Sarah in June 2024 to enable testing of the developed algorithms. Additional three trajectories recorded from Saskia in 2023 are used to test the algorithms. The algorithms are tested separately on the data of both of us. This allows us to draw a conclusion whether the algorithms are able to differentiate walking patterns from different people. The test data from Saskia consist of 6 trajectories and a total of 8'559 attributed points. The test data from Sarah consists of 9 trajectories and a total of 17'648 attributed points. 

### Preparation

The data exported from Strava has the format gpx. The single activities are read and written into a data frame. IDs and descriptions for recognition are assigned to the single activities. The activities are then combined to one data frame and turned into a spatial object, which is then exported for manual classification. In QGIS, every point is given either the attribute shopping, recreation or commuting. The points are selected by location using an Open Street Map basemap. The activities are then again imported, turned into a spatial object and reprojected to LV95.

```{r Preparation-and-export-for-GIS, fig.keep = "none", message=FALSE}
#| code-summary: Preparation
# read training activities
myfiles <- list.files("activities/.", pattern = "*.gpx")

for (i in 1:length(myfiles)){
  filename <- paste0("act", i)
  wd <- paste0("activities/", myfiles[i])
  assign(filename, htmlTreeParse(file = wd, useInternalNodes = TRUE))
}

# function to parse activities and write into data frame
built_df <- function(activity) {
  # get coordinates
  coords <- xpathSApply(doc = activity, path = "//trkpt", fun = xmlAttrs)
  # get elevation
  elevation <- xpathSApply(doc = activity, path = "//trkpt/ele", fun = xmlValue)
  # get time
  time <- xpathApply(doc = activity, path = "//trkpt/time", fun = xmlValue)
  data.frame(
    lat = as.numeric(coords["lat", ]),
    lon = as.numeric(coords["lon", ]),
    ts_POSIXct = ymd_hms(time, tz = "UTC"),
    elevation = as.numeric(elevation)
  )
}
# convert files to dataframe
act1_df <- built_df(act1)
act2_df <- built_df(act2)
act3_df <- built_df(act3)
act4_df <- built_df(act4)
act5_df <- built_df(act5)
act6_df <- built_df(act6)
act7_df <- built_df(act7)
act8_df <- built_df(act8)
act9_df <- built_df(act9)
act10_df <- built_df(act10)
act11_df <- built_df(act11)
act12_df <- built_df(act12)

# assign ID and description to single files
act1_df$ID <- "test_1"
act1_df$ID_text <- "test_Waedenswil_Reidbach_Zentrum"
act2_df$ID <- "test_2"
act2_df$ID_text <- "test_Waedenswil_Coop_Bahnhof"
act3_df$ID <- "test_3"
act3_df$ID_text <- "test_Waedenswil_Schloss_Mensa"
act4_df$ID <- "test_4"
act4_df$ID_text <- "test_Waedenswil_Gruental_Bahnhof1"
act5_df$ID <- "test_5"
act5_df$ID_text <- "test_Waedenswil_Gruental_Bahnhof2"
act6_df$ID <- "test_6"
act6_df$ID_text <- "test_Rueti_Home_Bahnhof_Coop_Home"
act7_df$ID <- "test_7"
act7_df$ID_text <- "test_test_Rapperswil_See_Bahnhof"
act8_df$ID <- "test_8"
act8_df$ID_text <- "test_Rueti_Home_Coop_Home"
act9_df$ID <- "test_9"
act9_df$ID_text <- "test_Neuhausen_Bahnhof_Rhein"
act10_df$ID <- "test_10"
act10_df$ID_text <- "test_Neuhausen_Rhein_Bahnhof"
act11_df$ID <- "test_11"
act11_df$ID_text <- "test_S-chanf"
act12_df$ID <- "test_12"
act12_df$ID_text <- "test_Regensdorf_Buero_Coop"

# function to convert data frame into sf object
df_to_sf <- function(df){
  st_as_sf(df, coords = c("lon", "lat"), crs = 4326 , remove = FALSE)
}

# combine all activitites into one data frame
test_activities_df <- rbind(act1_df, act2_df, act3_df, act4_df, act5_df, act6_df, act7_df, act8_df, act9_df, act10_df, act11_df, act12_df)

# turn data frame into sf object
test_activities_sf <- df_to_sf(test_activities_df)

# export sf object for setting attributes in GIS
# export_test_activities <- st_write(test_activities_sf, "test_activities.shp")
```

### Attribute based classification

For the attribute-based classification, the time-lag and distance between single locations are being calculated. These calculations are checked for outlines. As the time lag between two consecutive locations is mostly 1 s, all intervals bigger than 5 s are removed, as these are most likely a mistake. The same is true for the distance between two consecutive locations. All step length more than 5 m are removed. As attributes also depend on the spatial scale, the mean step is calculated using the two previous and two next distances. The speed is deducted from this mean step. The segmentation is done as described in @laube_how_2011. The threshold for moving is set to 1.5 m. This is based on the assumption that this equals around 3 - 4 steps, which can be interpreted as moving. Additionally, acceleration was calculated based on the calculated speed and time lag. After the calculation of the attributes per trajectories, a summary is done for each trajectory to find differences between activity types. Also, a summary over all activities is done to find differences between activity types. This information was used to set the thresholds. Based on the established differences, a classification is done. The classification is verified using a confusion matrix and its statistic output. The thresholds for classification are adapted until the best possible classification is reached.

```{r attribute-based, fig.keep = "none", message=FALSE, results='hide'}
#| code-summary: Attribute-based classification
#| 
# import csv with attributes and convert to sf
activities_classified <- read_delim("test_activities_attributiert.csv", ",")
activities_classified_sf <- df_to_sf(activities_classified)

# change crs of sf and specify attributes
activities_classified_sf <- st_transform(activities_classified_sf, crs = 2056)

activities_classified_sf <- activities_classified_sf |> 
  mutate(
    DateTime = as.POSIXct(ts_POSIXct),
    Attribute_factor = as.factor(Attribut)
  )

# Calculate attributes 
## calculate time lag  
difftime_secs <- function(later, now){
  as.numeric(difftime(later, now, units = "secs"))
}

activities_classified_sf <- activities_classified_sf |> 
  group_by(ID) |>
  mutate(
    timelag_sec = difftime_secs(lead(DateTime,), DateTime)
  )

## calculate distance between locations
distance_by_element <- function(later, now){
  as.numeric(
    st_distance(later, now, by_element = TRUE)
  )
}

activities_classified_sf <- activities_classified_sf |> 
  group_by(ID) |>
  mutate(
    steplenght = distance_by_element(lag(geometry), geometry)
  )

## Check plausibility of calculated parameters
plot(activities_classified_sf$timelag_sec)
plot(activities_classified_sf$steplenght)
boxplot(activities_classified_sf$timelag_sec)
boxplot(activities_classified_sf$steplenght)
summary(activities_classified_sf$timelag_sec)
summary(activities_classified_sf$steplenght)

# based on this check, remove all timelag > 5 and steplenght > 5
outliers_timelag <- filter(activities_classified_sf, timelag_sec >= 5)
activities_classified_sf <- activities_classified_sf[which(activities_classified_sf$timelag_sec <= 5),]
outliers_steplenght <- filter(activities_classified_sf, steplenght >= 5)
activities_classified_sf <- activities_classified_sf[which(activities_classified_sf$steplenght <= 5),]

# plot again to make sure it's better
plot(activities_classified_sf$timelag_sec)
plot(activities_classified_sf$steplenght)
boxplot(activities_classified_sf$timelag_sec)
boxplot(activities_classified_sf$steplenght)

# Segmentation
# Specify a temporal window for mean step
activities_classified_sf <- activities_classified_sf |> 
  group_by(ID) |>
  mutate(
    nMinus2 = distance_by_element(lag(geometry, 2), geometry),  
    nMinus1 = distance_by_element(lag(geometry, 1), geometry),  
    nPlus1  = distance_by_element(geometry, lead(geometry, 1)), 
    nPlus2  = distance_by_element(geometry, lead(geometry, 2))  
  )

# calculate mean step
activities_classified_sf <- activities_classified_sf |> 
  group_by(ID) |>
  rowwise() |>
  mutate(
    stepMean = mean(c(nMinus2, nMinus1, nPlus1, nPlus2))
  ) |>
  ungroup()

# calculate mean speed
activities_classified_sf <- activities_classified_sf |> 
  group_by(ID) |>
  mutate(
    speedMean = stepMean/timelag_sec
  )

# Explore mean step to define threshold 
hist(activities_classified_sf$stepMean)
boxplot(activities_classified_sf$stepMean)
summary(activities_classified_sf$stepMean)

# apply threshold
activities_classified_sf <- activities_classified_sf |> 
  group_by(ID) |>
  mutate(static = stepMean <  1.5)

# give segments an ID
rle_id <- function(vec) {
  x <- rle(vec)$lengths
  as.factor(rep(seq_along(x), times = x))
}

activities_classified_sf <- activities_classified_sf |> 
  group_by(ID) |>
  mutate(segment_id = rle_id(static))|> 
  ungroup()

# extract single trajectories
traj1 <- filter(activities_classified_sf, ID == "test_1")
traj2 <- filter(activities_classified_sf, ID == "test_2")
traj3 <- filter(activities_classified_sf, ID == "test_3")
traj4 <- filter(activities_classified_sf, ID == "test_4")
traj5 <- filter(activities_classified_sf, ID == "test_5")
traj6 <- filter(activities_classified_sf, ID == "test_6")
traj7 <- filter(activities_classified_sf, ID == "test_7")
traj8 <- filter(activities_classified_sf, ID == "test_8")
traj9 <- filter(activities_classified_sf, ID == "test_9")
traj10 <- filter(activities_classified_sf, ID == "test_10")
traj11 <- filter(activities_classified_sf, ID == "test_11")
traj12 <- filter(activities_classified_sf, ID == "test_12")


# Summarize by true activity
summary <- activities_classified_sf |> 
  group_by(ID) |> 
  group_by(Attribute_factor) |> 
  summarize(stops = sum(static, na.rm = TRUE), 
            not_stops = sum(!static, na.rm = TRUE),
            mean_speed = mean(speedMean, na.rm =TRUE),
            mean_step = mean(stepMean, na.rm = TRUE))

# summarize per trajectory
stops_traj1 <- traj1 |> 
  group_by(Attribute_factor) |> 
  summarize(stops = sum(static, na.rm = TRUE),
            not_stops = sum(!static, na.rm = TRUE),
            mean_speed = mean(speedMean, na.rm =TRUE),
            mean_step = mean(stepMean, na.rm = TRUE))
stops_traj2 <- traj2 |> 
  group_by(Attribute_factor) |> 
  summarize(stops = sum(static, na.rm = TRUE),
            not_stops = sum(!static, na.rm = TRUE),
            mean_speed = mean(speedMean, na.rm =TRUE),
            mean_step = mean(stepMean, na.rm = TRUE))
stops_traj3 <- traj3 |> 
  group_by(Attribute_factor) |> 
  summarize(stops = sum(static, na.rm = TRUE), 
            not_stops = sum(!static, na.rm = TRUE),
            mean_speed = mean(speedMean, na.rm =TRUE),
            mean_step = mean(stepMean, na.rm = TRUE))
stops_traj4 <- traj4 |> 
  group_by(Attribute_factor) |> 
  summarize(stops = sum(static, na.rm = TRUE),
            not_stops = sum(!static, na.rm = TRUE),
            mean_speed = mean(speedMean, na.rm =TRUE),
            mean_step = mean(stepMean, na.rm = TRUE))
stops_traj5 <- traj5 |> 
  group_by(Attribute_factor) |> 
  summarize(stops = sum(static, na.rm = TRUE),
            not_stops = sum(!static, na.rm = TRUE),
            mean_speed = mean(speedMean, na.rm =TRUE),
            mean_step = mean(stepMean, na.rm = TRUE))
stops_traj6 <- traj6 |> 
  group_by(Attribute_factor) |> 
  summarize(stops = sum(static, na.rm = TRUE), 
            not_stops = sum(!static, na.rm = TRUE),
            mean_speed = mean(speedMean, na.rm =TRUE),
            mean_step = mean(stepMean, na.rm = TRUE))
stops_traj7 <- traj7 |> 
  group_by(Attribute_factor) |> 
  summarize(stops = sum(static, na.rm = TRUE), 
            not_stops = sum(!static, na.rm = TRUE),
            mean_speed = mean(speedMean, na.rm =TRUE),
            mean_step = mean(stepMean, na.rm = TRUE))
stops_traj8 <- traj8 |> 
  group_by(Attribute_factor) |> 
  summarize(stops = sum(static, na.rm = TRUE), 
            not_stops = sum(!static, na.rm = TRUE),
            mean_speed = mean(speedMean, na.rm =TRUE),
            mean_step = mean(stepMean, na.rm = TRUE))
stops_traj9 <- traj9 |> 
  group_by(Attribute_factor) |> 
  summarize(stops = sum(static, na.rm = TRUE), 
            not_stops = sum(!static, na.rm = TRUE),
            mean_speed = mean(speedMean, na.rm =TRUE),
            mean_step = mean(stepMean, na.rm = TRUE))
stops_traj10 <- traj10 |> 
  group_by(Attribute_factor) |> 
  summarize(stops = sum(static, na.rm = TRUE),
            not_stops = sum(!static, na.rm = TRUE),
            mean_speed = mean(speedMean, na.rm =TRUE),
            mean_step = mean(stepMean, na.rm = TRUE))
stops_traj11 <- traj11 |> 
  group_by(Attribute_factor) |> 
  summarize(stops = sum(static, na.rm = TRUE), 
            not_stops = sum(!static, na.rm = TRUE),
            mean_speed = mean(speedMean, na.rm =TRUE),
            mean_step = mean(stepMean, na.rm = TRUE))
stops_traj12 <- traj12 |> 
  group_by(Attribute_factor) |> 
  summarize(stops = sum(static, na.rm = TRUE),
            not_stops = sum(!static, na.rm = TRUE),
            mean_speed = mean(speedMean, na.rm =TRUE),
            mean_step = mean(stepMean, na.rm = TRUE))

plot(stops~Attribute_factor, data = summary)
plot(not_stops~Attribute_factor, data = summary)
summary$stop_ratio <- summary$not_stops/summary$stops
plot(stop_ratio~Attribute_factor, data = summary)

# function to calculate acceleration
acceleration <- function(s1, s2, t){
  as.numeric((s2-s1)/(t))
}

# calculate acceleration 
activities_classified_sf <- activities_classified_sf |> 
mutate(acceleration = 
    acceleration(lag(speedMean), speedMean, timelag_sec))

# summarize attributes per attribute factor
summary <- activities_classified_sf |> 
  group_by(ID) |> 
  group_by(Attribute_factor) |> 
  summarize(stops = sum(static, na.rm = TRUE), 
            not_stops = sum(!static, na.rm = TRUE),
            stop_ratio = not_stops/stops,
            mean_speed = mean(speedMean, na.rm =TRUE),
            mean_step = mean(stepMean, na.rm = TRUE),
            mean_acceleration = mean(acceleration, na.rm = TRUE),
            mean_lenght = length(segment_id)
            ) |> 
  ungroup()

# Export csv for CAMA workflow
# st_write(activities_classified_sf, "test_activities_with_attributes_korrigiert.csv")

# create new id to group by for classification
activities_for_classification <- activities_classified_sf |> 
  mutate(combi_ID = paste(ID, segment_id, sep = "_"))
  

# summarize with new id
test_classification <- activities_for_classification |> 
  group_by(combi_ID) |> 
  summarize(mean_acceleration = mean(acceleration, na.rm = TRUE),
            mean_speed = mean(speedMean, na.rm =TRUE),
            mean_step = mean(stepMean, na.rm = TRUE),
            lenght = length(segment_id)
            ) |> 
  ungroup()

# apply thresholds for attributes
test_classification <- test_classification |> 
  mutate(travel = if_else(mean_speed > 1.7 & mean_speed < 4
                          & mean_step > 1.7 & mean_step < 4
                          & mean_acceleration < 0.003,  1 ,  0 ),
         recreation = if_else(travel %in% c( 0 ) 
                              & mean_speed > 1.1  & mean_speed < 1.7
                              & mean_step > 1.2 & mean_step < 1.7
                              & mean_acceleration < 0.003,  1 ,  0 ),
         shopping = if_else(travel %in% c( 0 ) 
                            & recreation %in% c( 0 )
                            & mean_speed > 5 |  mean_speed < 1.1
                            & mean_step > 5 | mean_step < 1.2
                            & mean_acceleration > 0.01
                              ,  1 ,  0 ))

# create new attribute with activity as character based on applied thresholds
test_classification <- test_classification |> 
  mutate(activity = if_else(shopping == 1, "shopping", 
                            if_else(recreation == 1, "recreation", "travel"),"NA"))

# remove points where classification was not possible
test_classification <- na.omit(test_classification)

# define activity as factor
test_classification <- test_classification |> 
  mutate(activity_factor = as.factor(activity)) 
  
# join classified table with sf object
test_activities_classified <- st_join(activities_classified_sf, test_classification, left = TRUE)

# calculate confusion matrix to test classification
confus <-conf_mat(data = test_activities_classified, truth = Attribute_factor, estimate = activity_factor)
```

## Results

### Attribut based classification

#### Test data

Despite extensive testing and adapting of the thresholds, it was not possible to correctly classify all activities. Based on the attributes speed, step length and acceleration, activities were hard to distinguish. 49 points could not be classified and were removed before computing the confusion matrix. The overall accuracy with the test data is 59 %. Sensitivity is highest for the class travel (0.6), specificity is highest for the class shopping (0.97). Detection rate is highest for travel (0.54).

```{r confusion matrix, message=FALSE, results='hide', fig.cap="Confusion matrix for the training data"}
#| code-summary: confusion matrix test data
# get statistics for confusion matrix
confusionMatrix(test_activities_classified$Attribute_factor, test_activities_classified$activity_factor)

# plot confusion matrix for test data
autoplot(confus, type="heatmap")+
  scale_fill_gradient(low="#D6EAF8",high = "#2E86C1")+
  theme(legend.position = "right")+
  labs(fill="frequency")
```

#### Activity data Saskia

30 points could not be classified and were removed before computing the confusion matrix. The overall accuracy of the model for the activity data of Saskia is 33 %. Again, sensitivity is highest for travel (0.34), as well as the detection rate (0.33).

```{r attribute-based classification Saskias data, fig.keep = "none", message=FALSE, results='hide'}
#| code-summary: Attribute-based classification Saskias data
# read activities
myfiles <- list.files("activities/activities_saskia.", pattern = "*.gpx")

for (i in 1:length(myfiles)){
  filename <- paste0("saskia_", i)
  wd <- paste0("activities/activities_saskia/", myfiles[i])
  assign(filename, htmlTreeParse(file = wd, useInternalNodes = TRUE))
}

# convert files to dataframe
saskia_1_df <- built_df(saskia_1)
saskia_2_df <- built_df(saskia_2)
saskia_3_df <- built_df(saskia_3)
saskia_4_df <- built_df(saskia_4)
saskia_5_df <- built_df(saskia_5)
saskia_6_df <- built_df(saskia_6)

# assign ID to single files
saskia_1_df$ID <- "saskia__1"
saskia_1_df$ID_text <- "saskia_Pfaeffikon_Seedamm1"
saskia_2_df$ID <- "saskia__2"
saskia_2_df$ID_text <- "saskia_Pfaeffikon_Seedamm2"
saskia_3_df$ID <- "saskia__3"
saskia_3_df$ID_text <- "saskia_Regensdorf_Buero_Bahnhof"
saskia_4_df$ID <- "saskia__4"
saskia_4_df$ID_text <- "saskia_Rueti_Zentrum_Home"
saskia_5_df$ID <- "saskia__5"
saskia_5_df$ID_text <- "saskia_Rueti_Home_Bahnhof_Coop_Home"
saskia_6_df$ID <- "saskia__6"
saskia_6_df$ID_text <- "saskia_Waedenswil_Gruental_Bhf"

# combine all activitites to one data frame
activities_saskia_df <- rbind(saskia_1_df, saskia_2_df, saskia_3_df, saskia_4_df, saskia_5_df, saskia_6_df)

# turn data frame into sf object
activities_saskia_sf <- df_to_sf(activities_saskia_df)

# export sf object for setting attributes in GIS
# export_activities_saskia <- st_write(activities_saskia_sf, "activities_saskia.csv")

# import csv with attributes and convert to sf
activities_saskia_attributed <- read_delim("activities_saskia_attributiert.csv", ",")
activities_saskia_attributed_sf <- df_to_sf(activities_saskia_attributed)

# change crs of sf
activities_saskia_attributed_sf <- st_transform(activities_saskia_attributed_sf, crs = 2056)

# set attributes
activities_saskia_attributed_sf <- activities_saskia_attributed_sf |> 
  mutate(
    DateTime = as.POSIXct(ts_POSIXct),
    Attribute_factor = as.factor(Attribut)
  )

# calculate time lag
activities_saskia_attributed_sf <- activities_saskia_attributed_sf |> 
  group_by(ID) |>
  mutate(
    timelag_sec = difftime_secs(lead(DateTime,), DateTime)
  )

# calculate distance between locations
activities_saskia_attributed_sf <- activities_saskia_attributed_sf |> 
  group_by(ID) |>
  mutate(
    steplenght = distance_by_element(lag(geometry), geometry)
  )

# Check plausibility of calculated parameters
plot(activities_saskia_attributed_sf$timelag_sec)
plot(activities_saskia_attributed_sf$steplenght)
boxplot(activities_saskia_attributed_sf$timelag_sec)
boxplot(activities_saskia_attributed_sf$steplenght)
summary(activities_saskia_attributed_sf$timelag_sec)
summary(activities_saskia_attributed_sf$steplenght)

# based on this check, remove all timelag > 5 and steplenght > 5
outliers_timelag <- filter(activities_saskia_attributed_sf, timelag_sec >= 5)
activities_saskia_attributed_sf <- activities_saskia_attributed_sf[which(activities_saskia_attributed_sf$timelag_sec <= 5),]
outliers_steplenght <- filter(activities_saskia_attributed_sf, steplenght >= 5)
activities_saskia_attributed_sf <- activities_saskia_attributed_sf[which(activities_saskia_attributed_sf$steplenght <= 5),]

# plot again to make sure it's better
plot(activities_saskia_attributed_sf$timelag_sec)
plot(activities_saskia_attributed_sf$steplenght)
boxplot(activities_saskia_attributed_sf$timelag_sec)
boxplot(activities_saskia_attributed_sf$steplenght)


# Segmentation
# Specify a temporal window for mean step
activities_saskia_attributed_sf <- activities_saskia_attributed_sf |> 
  group_by(ID) |>
  mutate(
    nMinus2 = distance_by_element(lag(geometry, 2), geometry),  
    nMinus1 = distance_by_element(lag(geometry, 1), geometry),  
    nPlus1  = distance_by_element(geometry, lead(geometry, 1)), 
    nPlus2  = distance_by_element(geometry, lead(geometry, 2))  
  )
# calculate mean step
activities_saskia_attributed_sf <- activities_saskia_attributed_sf |> 
  group_by(ID) |>
  rowwise() |>
  mutate(
    stepMean = mean(c(nMinus2, nMinus1, nPlus1, nPlus2))
  ) 

# calculate mean speed
activities_saskia_attributed_sf <- activities_saskia_attributed_sf |> 
  group_by(ID) |>
  mutate(
    speedMean = stepMean/timelag_sec
  )

# apply threshold (same as for test data)
activities_saskia_attributed_sf <- activities_saskia_attributed_sf |> 
  group_by(ID) |>
  mutate(static = stepMean <  1.5)

# give segments an ID
activities_saskia_attributed_sf <- activities_saskia_attributed_sf |> 
  group_by(ID) |>
  mutate(segment_id = rle_id(static)) |> 
  ungroup()

# calculate acceleration
activities_saskia_attributed_sf <- activities_saskia_attributed_sf |> 
  mutate(acceleration = 
           acceleration(lag(speedMean), speedMean, timelag_sec))

# create new id for classification
activities_saskia_for_classification <- activities_saskia_attributed_sf |> 
  mutate(combi_ID = paste(ID, segment_id, sep = "_"))

# group by new id and summarize attributes
saskia_classification <- activities_saskia_for_classification |> 
  group_by(combi_ID) |> 
  summarize(mean_acceleration = mean(acceleration, na.rm = TRUE),
            mean_speed = mean(speedMean, na.rm =TRUE),
            mean_step = mean(stepMean, na.rm = TRUE),
            lenght = length(segment_id)
  ) |> 
  ungroup()

# apply thresholds defined for test data
saskia_classification <- saskia_classification |> 
  mutate(travel = if_else(mean_speed > 1.7 & mean_speed < 4
                          & mean_step > 1.7 & mean_step < 4
                          & mean_acceleration < 0.003,  1 ,  0 ),
         recreation = if_else(travel %in% c( 0 ) 
                              & mean_speed > 1.1  & mean_speed < 1.7
                              & mean_step > 1.2 & mean_step < 1.7
                              & mean_acceleration < 0.003,  1 ,  0 ),
         shopping = if_else(travel %in% c( 0 ) 
                            & recreation %in% c( 0 )
                            & mean_speed > 5 |  mean_speed < 1.1
                            & mean_step > 5 | mean_step < 1.2
                            & mean_acceleration > 0.01
                            ,  1 ,  0 ))

# create attribute with activity as text
saskia_classification <- saskia_classification |> 
  mutate(activity = if_else(shopping == 1, "shopping", 
                            if_else(recreation == 1, "recreation", "travel"),"NA"))
# remove points that could not be classified
saskia_classification <- na.omit(saskia_classification)

# set classified activity as factor
saskia_classification <- saskia_classification |> 
  mutate(activity_factor = as.factor(activity)) 

# join classified table with sf object
saskia_activities_classified <- st_join(activities_saskia_attributed_sf, saskia_classification, left = TRUE)

# Export csv for other approaches
# st_write(saskia_activities_classified, "activities_saskia_with_attributes_classified.csv")

# generate confusion matrix for data
confus <-conf_mat(data = saskia_activities_classified, truth = Attribute_factor, estimate = activity_factor)

```

```{r confusion matrix Saskias data, message=FALSE, results='hide', fig.cap="Confusion matrix for Saskias data"}
#| code-summary: Confusion matrix for Saskias data
# get statistics of confusion matrix
confusionMatrix(saskia_activities_classified$Attribute_factor, saskia_activities_classified$activity_factor)

# plot confusion matrix
autoplot(confus, type="heatmap")+
  scale_fill_gradient(low="#D6EAF8",high = "#2E86C1")+
  theme(legend.position = "right")+
  labs(fill="frequency")
```

#### Activity data Sarah

51 points could not be classified and were removed before computing the confusion matrix. For Sarahs activities, the accuracy of the model is 19 %. The sensitivity for recreation is highest (0.71), the detection rate is highest for travel (0.16).

```{r attribute-based classification Sarahs data, fig.keep = "none", message=FALSE, results='hide'}
#| code-summary: Attribute-based classification Sarahs data
# import csv with attributes and convert to sf
activities_sarah_attributed <- read_delim("activities_sarah_attributiert.csv", ",")
activities_sarah_attributed_sf <- df_to_sf(activities_sarah_attributed)

# change crs of sf
activities_sarah_attributed_sf <- st_transform(activities_sarah_attributed_sf, crs = 2056)

# set attributes
activities_sarah_attributed_sf <- activities_sarah_attributed_sf |> 
  mutate(
    DateTime = as.POSIXct(ts_POSIXct),
    Attribute_factor = as.factor(Attribut)
  )

# calculate time lag
activities_sarah_attributed_sf <- activities_sarah_attributed_sf |> 
  group_by(ID) |>
  mutate(
    timelag_sec = difftime_secs(lead(DateTime,), DateTime)
  )

#calculate distance between locations
activities_sarah_attributed_sf <- activities_sarah_attributed_sf |> 
  group_by(ID) |>
  mutate(
    steplenght = distance_by_element(lag(geometry), geometry)
  )

# Check plausibility of calculated parameters
plot(activities_sarah_attributed_sf$timelag_sec)
plot(activities_sarah_attributed_sf$steplenght)
boxplot(activities_sarah_attributed_sf$timelag_sec)
boxplot(activities_sarah_attributed_sf$steplenght)
summary(activities_sarah_attributed_sf$timelag_sec)
summary(activities_sarah_attributed_sf$steplenght)

# based on this check, all timelag > 5 and steplenght > 5
outliers_timelag <- filter(activities_sarah_attributed_sf, timelag_sec >= 5)
activities_sarah_attributed_sf <- activities_sarah_attributed_sf[which(activities_sarah_attributed_sf$timelag_sec <= 5),]
outliers_steplenght <- filter(activities_sarah_attributed_sf, steplenght >= 5)
activities_sarah_attributed_sf <- activities_sarah_attributed_sf[which(activities_sarah_attributed_sf$steplenght <= 5),]

# plot again to make sure it's better
plot(activities_sarah_attributed_sf$timelag_sec)
plot(activities_sarah_attributed_sf$steplenght)
boxplot(activities_sarah_attributed_sf$timelag_sec)
boxplot(activities_sarah_attributed_sf$steplenght)

# Segmentation
# Specify a temporal window for mean step
activities_sarah_attributed_sf <- activities_sarah_attributed_sf |> 
  group_by(ID) |>
  mutate(
    nMinus2 = distance_by_element(lag(geometry, 2), geometry),  
    nMinus1 = distance_by_element(lag(geometry, 1), geometry),  
    nPlus1  = distance_by_element(geometry, lead(geometry, 1)), 
    nPlus2  = distance_by_element(geometry, lead(geometry, 2))  
  )
# calculate mean step
activities_sarah_attributed_sf <- activities_sarah_attributed_sf |> 
  group_by(ID) |>
  rowwise() |>
  mutate(
    stepMean = mean(c(nMinus2, nMinus1, nPlus1, nPlus2))
  ) 

# calculate mean speed
activities_sarah_attributed_sf <- activities_sarah_attributed_sf |> 
  group_by(ID) |>
  mutate(
    speedMean = stepMean/timelag_sec
  )

# apply threshold defined in test data
activities_sarah_attributed_sf <- activities_sarah_attributed_sf |> 
  group_by(ID) |>
  mutate(static = stepMean <  1.5)

# give segments an ID
activities_sarah_attributed_sf <- activities_sarah_attributed_sf |> 
  group_by(ID) |>
  mutate(segment_id = rle_id(static)) |> 
  ungroup()

# calculate acceleration ####
activities_sarah_attributed_sf <- activities_sarah_attributed_sf |> 
  mutate(acceleration = 
           acceleration(lag(speedMean), speedMean, timelag_sec))

# create new id to group for classification
activities_sarah_for_classification <- activities_sarah_attributed_sf |> 
  mutate(combi_ID = paste(ID, segment_id, sep = "_"))

# group by newly set id
sarah_classification <- activities_sarah_for_classification |> 
  group_by(combi_ID) |> 
  summarize(mean_acceleration = mean(acceleration, na.rm = TRUE),
            mean_speed = mean(speedMean, na.rm =TRUE),
            mean_step = mean(stepMean, na.rm = TRUE),
            lenght = length(segment_id)
  ) |> 
  ungroup()

# apply defined thresholds
sarah_classification <- sarah_classification |> 
  mutate(travel = if_else(mean_speed > 1.7 & mean_speed < 4
                          & mean_step > 1.7 & mean_step < 4
                          & mean_acceleration < 0.003,  1 ,  0 ),
         recreation = if_else(travel %in% c( 0 ) 
                              & mean_speed > 1.1  & mean_speed < 1.7
                              & mean_step > 1.2 & mean_step < 1.7
                              & mean_acceleration < 0.003,  1 ,  0 ),
         shopping = if_else(travel %in% c( 0 ) 
                            & recreation %in% c( 0 )
                            & mean_speed > 5 |  mean_speed < 1.1
                            & mean_step > 5 | mean_step < 1.2
                            & mean_acceleration > 0.01
                            ,  1 ,  0 ))

# get attribute activity as text
sarah_classification <- sarah_classification |> 
  mutate(activity = if_else(shopping == 1, "shopping", 
                            if_else(recreation == 1, "recreation", "travel"),"NA"))

# remove points that could not be classified
sarah_classification <- na.omit(sarah_classification)

# set classified activity as factor
sarah_classification <- sarah_classification |> 
  mutate(activity_factor = as.factor(activity)) 

# join classification table with sf object
sarah_activities_classified <- st_join(activities_sarah_attributed_sf, sarah_classification, left = TRUE)

# calcualte confusion matrix
confus <-conf_mat(data = sarah_activities_classified, truth = Attribute_factor, estimate = activity_factor)
```

```{r confusion matrix Sarahs data, message=FALSE, results='hide', fig.cap="Confusion matrix for Sarahs data"}
#| code-summary: Confusion matrix Sarahs data

# get statitics for confusion matrix
confusionMatrix(sarah_activities_classified$Attribute_factor, sarah_activities_classified$activity_factor)

# plot confusion matrix
autoplot(confus, type="heatmap")+
  scale_fill_gradient(low="#D6EAF8",high = "#2E86C1")+
  theme(legend.position = "right")+
  labs(fill="frequency")

```

## Discussion

## Appendix

### Wordcount

<!-- after installing the wordcountadding, remove the line "#| eval: false" -->

```{r}
wordcountaddin::word_count("index.qmd")
```
